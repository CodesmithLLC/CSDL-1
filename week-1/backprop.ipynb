{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Understanding-Gradient-Descent-and-Backpropogation\" data-toc-modified-id=\"Understanding-Gradient-Descent-and-Backpropogation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Understanding Gradient Descent and Backpropogation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loss-Functions\" data-toc-modified-id=\"Loss-Functions-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Loss Functions</a></span></li><li><span><a href=\"#An-Analogy:-you-are-standing-on-a-hill\" data-toc-modified-id=\"An-Analogy:-you-are-standing-on-a-hill-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>An Analogy: you are standing on a hill</a></span></li><li><span><a href=\"#Gradient-Descent\" data-toc-modified-id=\"Gradient-Descent-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Gradient Descent</a></span></li><li><span><a href=\"#Calculating-$--\\nabla-C$\" data-toc-modified-id=\"Calculating-$--\\nabla-C$-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Calculating $- \\nabla C$</a></span></li><li><span><a href=\"#A-Refined-Definition-of-Backpropogation\" data-toc-modified-id=\"A-Refined-Definition-of-Backpropogation-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>A Refined Definition of Backpropogation</a></span></li></ul></li><li><span><a href=\"#Network-Notation-Conventions-and-Activation-Functions\" data-toc-modified-id=\"Network-Notation-Conventions-and-Activation-Functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Network Notation Conventions and Activation Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Notation:-weights,-bias,-and-weighted-input\" data-toc-modified-id=\"Notation:-weights,-bias,-and-weighted-input-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Notation: weights, bias, and weighted input</a></span></li><li><span><a href=\"#Activation-Functions\" data-toc-modified-id=\"Activation-Functions-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Activation Functions</a></span></li><li><span><a href=\"#Code-Challenge:-sigmoid_activation\" data-toc-modified-id=\"Code-Challenge:-sigmoid_activation-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Code Challenge: <code>sigmoid_activation</code></a></span></li><li><span><a href=\"#Code-Challenge:-sigmoid_derivative\" data-toc-modified-id=\"Code-Challenge:-sigmoid_derivative-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Code Challenge: <code>sigmoid_derivative</code></a></span></li><li><span><a href=\"#Notation:-activations,-vectors,-and-matrices\" data-toc-modified-id=\"Notation:-activations,-vectors,-and-matrices-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Notation: activations, vectors, and matrices</a></span></li><li><span><a href=\"#Code-Challenge:-activation-and-activation_deriv\" data-toc-modified-id=\"Code-Challenge:-activation-and-activation_deriv-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Code Challenge: <code>activation</code> and <code>activation_deriv</code></a></span></li></ul></li><li><span><a href=\"#Mean-Squared-Error-and-its-Gradient\" data-toc-modified-id=\"Mean-Squared-Error-and-its-Gradient-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Mean Squared Error and its Gradient</a></span><ul class=\"toc-item\"><li><span><a href=\"#Code-Challenge:-mse\" data-toc-modified-id=\"Code-Challenge:-mse-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Code Challenge: <code>mse</code></a></span></li><li><span><a href=\"#Goal:-Gradient-of-Mean-Squared-Error\" data-toc-modified-id=\"Goal:-Gradient-of-Mean-Squared-Error-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Goal: Gradient of Mean Squared Error</a></span></li><li><span><a href=\"#Code-Challenge:-mse_grad\" data-toc-modified-id=\"Code-Challenge:-mse_grad-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Code Challenge: <code>mse_grad</code></a></span></li><li><span><a href=\"#Neuron-Error\" data-toc-modified-id=\"Neuron-Error-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Neuron Error</a></span></li><li><span><a href=\"#Plan-for-implementing-backprop\" data-toc-modified-id=\"Plan-for-implementing-backprop-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Plan for implementing backprop</a></span></li></ul></li><li><span><a href=\"#Implementing-Backpropogation\" data-toc-modified-id=\"Implementing-Backpropogation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Implementing Backpropogation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Code-Challenge:-final_layer_error\" data-toc-modified-id=\"Code-Challenge:-final_layer_error-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Code Challenge: <code>final_layer_error</code></a></span></li><li><span><a href=\"#Code-Challenge:-hidden_layer_error\" data-toc-modified-id=\"Code-Challenge:-hidden_layer_error-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Code Challenge: <code>hidden_layer_error</code></a></span></li><li><span><a href=\"#Code-Challenge:-weights_grad\" data-toc-modified-id=\"Code-Challenge:-weights_grad-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Code Challenge: <code>weights_grad</code></a></span></li><li><span><a href=\"#Code-Challenge:-backprop\" data-toc-modified-id=\"Code-Challenge:-backprop-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Code Challenge: <code>backprop</code></a></span></li><li><span><a href=\"#Code-Challenge:-update_parameters\" data-toc-modified-id=\"Code-Challenge:-update_parameters-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Code Challenge: <code>update_parameters</code></a></span></li><li><span><a href=\"#Code-Challenge:-train\" data-toc-modified-id=\"Code-Challenge:-train-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Code Challenge: <code>train</code></a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Understanding Gradient Descent and Backpropogation\n",
    "So far, we've created neural networks that require an engineer to provide weights and biases that cause the network to perform in a desirable way. This is manageable for very small networks that perform tasks like XOR. But imagine a network that accepts images as input and is expected to classify the image as either a dog or a cat. How would we possibly designate the weights for this network ourselves?\n",
    "\n",
    "We would prefer to specify a network architecture (i.e. specify the number of layers and the number of neurons in each layer), and then initialize the network with a set of random weights and biases. This network will surely perform terribly at classifying our images. But through a process of slowly learning weights and biases that accomplish slightly more accurate results, we can end up with a network, along with a set of weights and biases for the network, that performs stunningly accurate classification of our images.\n",
    "\n",
    "The process by which a neural network learns a better set of weights is called backpropagation. The name backpropagation describes the process - we begin by updating the weights and biases in the final layer of the network, and work backwards layer by layer, till we've updated the weights and biases in the first hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make a network perform better, we need to specify some measurement of how well our network is performing. Any such measurement is called a **loss function** or a **cost function**. We will usually use the variable `C` or `J` to denote loss functions.\n",
    "\n",
    "Let's suppose we want to train a dense neural network on a fixed set of training data. Given this fixed set of training data, `X_train`, and corresponding labels, `y_train`, we will consider a loss function to be a function that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Takes the set of model parameters (i.e. weights and biases),`P`, as input\n",
    "1. Using the parameter values specified by `P`, passes `X_train` through the model to acquire a set of predictions, `y_pred`\n",
    "1. Outputs a number that represents how far off `y_pred` is from the correct labels, `y_train`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are many possible loss functions, and each of them differs from the others in how they assess the distance between `y_pred` and `y_train`.\n",
    "\n",
    "All loss functions share something important in common: a higher output from the loss function means that `y_pred` is further away from the desired labels `y_train`, and hence indicates worse performance on the training set. This give us a strategy for training our model: **find a set of parameters that minimizes the output from the loss function**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a model with two parameters, $\\theta_0$ and $\\theta_1$, and a loss function $J$. If we mapped out the value of $J$ across the space of possible parameter values, we might see something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gradient descent example](images/gradient-descent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this map, we can tell that if we set the model parameters to roughly $(\\theta_0,\\ \\theta_1) = (0.7,\\ 0.6)$, the loss function $J$ is at a peak/local maximum. This means the model performs very badly with the parameter values $(0.7,0.6)$. The model performs best when the parameters are set to values that correspond with low valleys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, it's very computationally difficult to search the entire space of possible parameter values for the lowest valley. Most deep learning models will take a different approach to find parameter values that lead to a small evaluation of the loss function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Analogy: you are standing on a hill\n",
    "Suppose you are standing on a hillside, surrounded by an expansive landscape of other hills and valleys. The higher up you are, the harder it is to breathe, so you would like to walk to the lowest point possible. The country side is so vast, though, that it would take a very long time to find the absolute lowest valley. So instead of scowering the entire landscape for the lowest point, you decide to take a step downhill. Before every step, you assess which direction is sloping downhill fastest, and you take a step in that direction. You keep doing this until you have reached the bottom of a valley. You settle there, now that you can breathe much more easily, even though there might be a lower valley a few hills over.\n",
    "\n",
    "Let's rephrase this in terms of functions. We can consider the height of the hill you are standing on as a function of your latitude and longitude. If you are at latitude `x` and longitude `y`, we call the height of the hill at that point `Height(x,y)`. Now, consider a second function that helps us determine which direction to step. We will call this function `Downhill`. `Downhill` accepts a latutude and a longitude, and it tells us which direction is downhill at that latitude and longitude. So, if we are at `latitude=1` and `longitude=2`, and we assess `Downhill(1, 2) == (-0.1, .3)`, this means that we can walk downhill fastest by decreasing our latitude by `0.1` and increasing our longitude by `0.3`. So, we would take a step and wind up at `latitude=0.9` and `longitude=2.3`.\n",
    "\n",
    "This scenario with the hill corresponds to how we would train a model that has two parameters. In this analogy, the parameters of the model are like your latitude and logitude. Given your latitude and longitude, we can use the function `Height` to figure out your altitude. Similarly, we use a loss function, `C`, to determine how badly the model is performing based on its current parameters. The function `Downhill`, which tells us how to change our latitude and longitude in order to take a step downhill in the steepest direction, is analogous to the function $-\\nabla C$, called the gradient of `C` (or more precisely, the negative gradient of `C`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "The goal of gradient descent, in the hill analogy, is to compute (or at least approximate) the function `Downhill`. In the case of our models, the goal of gradient descent is to compute $- \\nabla C$. If we are able to assess this function, we know how to adjust our parameters in order to \"step downhill in the steepest direction\", or \"improve our model's performance most dramatically\".\n",
    "\n",
    "In the hill scenario, we can't be sure that we ended up in the lowest valley. But our approach of taking a step in the steepest downhill direction was still a pretty good strategy - it would have taken us ages to explore the entire landscape of hills and valleys, but at each point on the hill, it takes us very little time to assess the local landscape and use our senses to determine which direction is downhill. Similarly, gradient descent doesn't ensure that we end up with the best possible parameters for our model. There are algorithms that exist that can find the global minimum of our loss function, i.e. \"scower the entire landscape of possible parameters\", but they take a very long time. It is much faster to assess the local landscape of parameters that are similar to our current parameters, and compute which small change we can make to our parameters that makes our loss function decrease most rapidly. We repeat this step until we find ourselves at the bottom of a valley (i.e. making any change to our parameters will cause our loss function to increase). Recall the image of gradient descent from earlier:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gradient descent example](images/gradient-descent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two separate paths depict how the gradient descent algorithm might cause us to settle into different local minima of our loss function depending on our initial choice of parameters. In the hillside analogy, if we start walking downhill from one side of the hill, we might end up in a different valley than if we had started out walking downhill from just a bit to the left or right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating $- \\nabla C$\n",
    "\n",
    "Let's continue with our hillside analogy. Suppose we are standing on a hill at `latitude=1` and `longitude=2`, and our current altidude is `Height(1,2) == 5`. Suppose I begin walking due north (i.e. my latitude is increasing while my longitude remains constant). As I walk north, I am walking slightly uphill at a rate of 0.1 meters up for each meter of increased latitude (for the sake of this example, let's suppose latitude is measured in meters!). We can state the same thing using mathematical notation:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\n",
    "    \\partial\\ \\text{Height}\n",
    "}{\n",
    "\\partial\\ \\text{latitude}\n",
    "}\n",
    "\\Big( 1,2 \\Big) = 0.1\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "This statement is read as \"The partial derivative of Height with respect to latitude at (1,2) is 0.1\". This means, as we walk due north from the point (1,2), our height is increasing by 0.1 meters for each meter our latitude increases.\n",
    "\n",
    "Now, instead of walking north, we walk due east from the point (1,2) (i.e. we increase our longitude while holding our latitude constant). As we walk, our height is decreasing at a rate of -0.3 meters for every meter our longitude increases. That is:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial\\ \\text{Height}}{\\partial\\ \\text{longitude}}\\Big(1,2\\Big) = -0.3\n",
    "\\label{eq2}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "We express this equation in English as: the partial derivative of Height with respect to longitude is -0.3.\n",
    "\n",
    "We can use these two facts, $\\frac{\\partial\\ \\text{Height}}{\\partial\\ \\text{latitude}}\\big(1,2\\big) = 0.1$ and $\\frac{\\partial\\ \\text{Height}}{\\partial\\ \\text{longitude}}\\Big(1,2\\Big) = -0.3$, to figure out which direction to walk that will lead us uphill at the steepest rate, according to the equation below:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\text{Uphill}(x,y) = \\nabla \\text{Height} (x,y) := \\Big(\\frac{\\partial\\ \\text{Height}}{\\partial\\ \\text{latitude}}\\big(x,y\\big),\\ \\frac{\\partial\\ \\text{Height}}{\\partial\\ \\text{longitude}}\\big(x,y\\big)\\Big)\n",
    "\\label{eq3}\n",
    "\\end{equation}\n",
    "$$.\n",
    "\n",
    "In particular, we see that `Uphill(1,2) == (0.1, -0.3)`. This means that we are moving uphill most quickly if we walk 0.1 meters north for each 0.3 meters we walk west.\n",
    "\n",
    "We would like to avoid walking uphill at all costs. In fact, we'd like to walk downhill as quickly as possible! We will therefore update our position by taking a step in the opposite direction of $\\text{Uphill} = \\nabla \\text{Height}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Refined Definition of Backpropogation\n",
    "\n",
    "Backpropogation is the process by which we:\n",
    "\n",
    "1. Compute the gradient of the loss function of a neural network with respect to the network's wieghts and biases\n",
    "1. Update the weights and biases accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Notation Conventions and Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section, we will work through an example of how to perform backpropogation. Before getting starting, we'll need to establish some notation that will make talking about our networks much simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation: weights, bias, and weighted input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a neural network with weights and biases initialized like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/network-for-loss-ex.png\" alt=\"Network with weights and bias\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will refer to the input layer as layer 1, the hidden layer as layer 2, and the output layer as layer 3. We'd like a way to refer to each specific weight and each specific bias in this network. We will use this notational system:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $w_{jk}^l$: The weight from the $k^{th}$ neuron in the layer $(l - 1)$ to the $j^{th}$ neuron in the layer $l$.\n",
    "* $b^l_j$: The bias of the $j^{th}$ neuron in layer $l$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, in the network above, $w_{21}^2 = -0.2$ since the weight connecting the $2^{nd}$ neuron in layer 1 to the $1^{st}$ neuron in layer 2 is -0.2. The value $b^3_1 = -1.2$ since the bias of the first neuron in the third layer is -1.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to feed the observation $(x,\\ y) = (0.5,\\ 1)$ forward through the network. We have the following notation to describe the weighted input of each neuron in the network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $z^l_j$: The weighted input of the $j^{th}$ neuron in layer $l$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we pass $(0.5,\\ 1)$ through our network, $z^2_1 = 0.45$ since $0.5*0.5\\ +\\ 0.7*1\\ -\\ 0.5 = 0.45$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An **activation function** is a function that accepts the weighted input of a neuron and outputs the activation of a nueron. In the first pair programming unit, we used an activation function that would output a 0 if the weighted input was less than 0, and otherwise would output a 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/non-differentiable-activation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we continued to use this activation function, it would pose a serious problem for our gradient descent training strategy. With this activation function, the gradient of any cost function we use will be null everywhere. Let's consider why. If I change a single weight by just a little bit, the weighted input to its neuron changes just a little bit. With a small change in weighted input, the neuron's activation doesn't change at all! This means a small change in a weight won't produce different output from a neuron, and therefore won't cause any change in the evaluation of loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to use an activation function that is:\n",
    "\n",
    "1. differentiable\n",
    "1. Has non-zero derivative almost everywhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation function we'll use today is called a sigmoid activation function. It looks like a smoothed out version of the step function we used in the previous unit:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/sigmoid-activation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Challenge: `sigmoid_activation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the function below. Your function will accept a number, `z`, that represents the weighted input of a neuron. Your function should ouput the value $$\\sigma(z) = \\frac{1}{1 + e^{-z}}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_activation(z):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Challenge: `sigmoid_derivative`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that accepts the weighted input of a neuron, `z`, and returns the derivative of the sigmoid activation function at `z` (i.e. the slope of the sigmoid function at `z`). The derivative of the sigmoid function is expressed as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sigma'(z) = \\sigma(z)\\ *\\ (1 - \\sigma(z))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph of this function looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/sigma-derivative.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(z):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation: activations, vectors, and matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We'll use the variable $\\sigma$ (Greek letter sigma) to denote activation functions.\n",
    "* $a^l_j$: The activation of the $j^{th}$ neuron in layer $l$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a rule, we know that $a^l_j = \\sigma(z^l_j)$. Convince yourself this is true before moving on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we feed a single observation in the training set through a network. Frequently, we will want to talk about all the activations in a layer, rather than the activation of each individual neuron. For this reason, we'll use the following notations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $a^l$: a NumPy array with shape `(number_neurons_in_layer_l, 1)` that contains the activations of each neuron in layer $l$. The single entry in the $k^{th}$ row denotes the activation of the $k^{th}$ neuron when an observation is fed through network.\n",
    "* $z^l$: the weighted inputs of each neuron in layer $l$. Similarly, its shape will be `(number_neurons_in_layer_l, 1)`.\n",
    "* $b^l$: the biases of each nueron in layer $l$. This will also have the shape `(number_neurons_in_layer, 1)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the notation for the activation function somewhat loosely. We'd like to be able to use a **vectorized** version of $\\sigma$. That is, we will apply the $\\sigma$ function to vectors of weighted inputs, instead of just individual weighted inputs. For example, we will write the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sigma(z^l) = \\sigma\\left( \\begin{bmatrix} z^l_1 \\\\ \\vdots \\\\ z^l_n \\end{bmatrix} \\right) = \\begin{bmatrix} \\sigma(z^l_1) \\\\ \\vdots \\\\ \\sigma(z^l_n) \\end{bmatrix} = a^l$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want a way to refer to all of the weights in a layer. We will use the following notation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $w^l$: A NumPy array with shape `(number_neurons_in_layer_l, number_neurons_in_layer_l-1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you move on, you should convince yourself that the following statements are true:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $w^l_{jk}$ is the element stored at the coordinate $(j,k)$ in the matrix $w^l$\n",
    "* $z^l = w^la^{l-1} + b^l$, where ($w^la^{l-1}$) denotes matrix multiplication and ($+$) is vector addition\n",
    "* $a^l = \\sigma(w^la^{l-1} + b^l)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Challenge: `activation` and `activation_deriv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refactor your `sigmoid_activation` and `sigmoid_derivative` functions so that they accept a numpy array of weight inputs. These functions are the same except they accept a numpy array of any shape and returns a numpy array of the same shape, but each element has had the $\\sigma$ or $\\sigma'$ function applied to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(z):\n",
    "    # Remember: z is a numpy array\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_deriv(z):\n",
    "    # Remember: z is a numpy array\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Squared Error and its Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use **mean squared error** as our loss function to train our neural network. Let's walk through the steps to compute the squared error for a single observation in the training set. Suppose we've got a dense neural net with $L$ layers. Then the squared error of the network for one observation in the training set is calculated this way:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Feed the observation forward through the network to obtain the activations of the output layer. This will be a column vector which we'll call $a^L$.\n",
    "1. Compute the Squared (Euclidean) distance between $a^L$ and the label vector, $y_{train}$. Call this value `distance`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an observation, $x$, we could write this equation as: $Squared Error(x) = \\| a^L(x) - y_{train}(x)\\|^2$. Here, the notation $\\| v \\|$ denotes the length of a vector $v$, so $\\| a^L(x) - y_{train}(x)\\|$ is the distance between the vector $a^L(x)$ and $y_{train}(x)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it's name implies, the mean squared error of the network is just the mean of squared error taken over all of the observations in the training set:\n",
    "\n",
    "$$MSE = \\frac{\\sum_x \\|a^L(x) - y_{train}(x)\\|^2}{number\\ of\\ observations}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose as an example we are training this network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/network-for-loss-ex.png\" alt=\"Network with weights and bias\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([\n",
    "    [1,2],\n",
    "    [3,4],\n",
    "    [5,6]\n",
    "])\n",
    "\n",
    "y_train = np.array([[0],[1],[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the mean squared error for this model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We feed each observation in `X_train` forward through the model to obtain $y_{pred} \\approx \\begin{bmatrix}0.378 \\\\ 0.434 \\\\ 0.472 \\end{bmatrix}$. Notice that the $k^{th}$ row of $y_{pred}$ corresponds $a^L(x_k)$, the activations of the output layer neurons for the $k^{th}$ observation in the training set.\n",
    "1. We compute the square of the distance between $y_{pred}$ and $y_{train}$ to get $distance \\approx .686$\n",
    "1. Since there are three observations in the training set, we divide the square distance by 3 to get $MSE \\approx .229$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Challenge: `mse`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that accepts two inputs, `y_pred` and `y_train`. They will each be NumPy arrays with shape `(number_observations, number_neurons_in_output_layer)`. Your function should return the resulting mean squared error of of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_pred, y_train):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal: Gradient of Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our eventual goal with backpropogation is to compute the value $\\frac{\\partial MSE}{\\partial w_{jk}^l}$ for every weight in the network, and the value $\\frac{\\partial MSE}{\\partial b_{j}^l}$ for every bias in the network. If we knew these values, we could update the value of each weight in the network like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$w_{jk}^l := w_{jk}^l - \\eta\\frac{\\partial MSE}{\\partial w_{jk}^l}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our analogy with the hilly landscape, the $MSE$ function is the function that outputs our altitude, and the value $\\frac{\\partial MSE}{\\partial w_{jk}^l}$ tells us how steeply our altitude increases if we change only the value $w_{jk}^l$ and keep everything else constant. The value $\\eta$ in this equation is the **learning rate**, a constant number that represents how big each of our steps downhill should be. We'll talk more about how to pick the learning rate a little later on. We'll use a similar rule to update each bias in the network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$b^l_j := b^l_j - \\eta \\frac{\\partial MSE}{\\partial b^l_j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Challenge: `mse_grad`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the backpropogation algorithm in order to calculate the partial derivatives of MSE with respect to each weight and bias in the network. It's much simpler, however, to compute the gradient of MSE with respect to the activations of the output layer, $a^L$. This value, written $\\nabla_{a}MSE$, represents the direction we would need to move the vector $a^L(x)$ in order for it to exactly equal $y_{train}(x\n",
    ")$. This function will be important for the backpropogation algorithm later on. In the code cell below, complete the function `mse_grad` that computes the value:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\nabla_{a}MSE(x) = a^L(x) - y_{train}(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Input**\n",
    "1. `a_L`: The result of feeding an observation in `X_train` forward through the network. It is a numpy array with shape `(number of neurons in final layer, 1)`\n",
    "1. `y`: The label for the training data (i.e. the desired activations for the output layer). This is also a numpy array with shape `(number of neurons in final layer, 1)`.\n",
    "\n",
    "**Function Output**\n",
    "1. `gradient`: The difference between `a_L` and `y`. It's a numpy array with the same shape as `a_L` and `y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_grad(a_L, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compute the values of the partial derivatives $\\frac{\\partial MSE}{\\partial w_{jk}^l}$ and $\\frac{\\partial MSE}{\\partial b_{j}^l}$, first we are going to use a measure of how much of the network's total error each individual neuron is responsible for. Suppose we feed a single observation in the training data through the network. Then we'll use the following notation to describe the error caused by each neuron:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\delta_j^l$: a number representing the amount of network error attributable to the $j^{th}$ neuron in the $l^{th}$ layer.\n",
    "* $\\delta^l$: a vector that holds the amount of error each neuron in the $l^{th}$ layer is responsible for. If there are $m$ neurons in layer $l$, then $\\delta^l = \\begin{bmatrix}\\delta^l_1 \\\\ \\vdots \\\\ \\delta^l_m\\end{bmatrix}$. Like $b^l$, $z^l$, and $a^l$, $\\delta^l$ is a column vector with shape `(number of neurons in layer l, 1)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan for implementing backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our plan for implementing backpropogation in a network with $L$ layers is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pick an observation, $x$, in the training set. Feed it forward through the network and record the weighted inputs ($z^l(x)$) of each layer and the activations ($a^l(x)$) of each layer. \n",
    "1. We'll start by computing the error of each neuron in the final layer of the network using the following formula:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\delta^L(x) = \\nabla_{a}MSE(x)\\ \\odot\\ \\sigma ' (z^L(x))\n",
    "\\end{equation}\n",
    "$$\n",
    "Note that the symbol $\\odot$ in this equation denotes the **Hadamard product** - it means component-wise multiplication and is the same thing as multiplying two numpy arrays with the same shape.\n",
    "1. Working backwards layer by layer, we'll compute the error in each of the remaining layers using the identity: $$\n",
    "\\begin{equation}\n",
    "\\delta^l(x) = \\left(w^{l + 1}\\right)^T \\delta^{l+1}(x)\\ \\odot\\ \\sigma ' (z^l(x))\n",
    "\\end{equation}\n",
    "$$\n",
    "1. Once we've calculated the error, $\\delta^l_j$, of each neuron in the network, we can find the partial derivative of MSE with respect to the biases according to the rule:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial MSE}{\\partial b^l_j} = \\delta^l_j\n",
    "\\end{equation}\n",
    "$$\n",
    "1. We also use the error values to find the partial derivative of MSE with respect to each of the weights in the network:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial MSE}{\\partial w^l_{jk}} = a^{l - 1}_k \\delta^l_j\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Backpropogation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Challenge: `final_layer_error`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that computes the error of each neuron in the final layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Input**\n",
    "1. `y`: label for one observation in the training set. Shape will be `(number of neurons in final layer, 1)`\n",
    "1. `a_L`: activations of the final layer. Shape will be `(number of neurons in the final layer, 1)`.\n",
    "1. `z_L`: The weighted input to the final layer of the network (i.e. $z^L$). Shape will be `(number of neurons in final layer, 1)`\n",
    "\n",
    "**Function Output**\n",
    "\n",
    "Your function should use your previous functions `mse_grad` and `activation_deriv` to output the value\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\delta^L(x) = \\nabla_{a}MSE(x)\\ \\odot\\ \\sigma ' (z^L(x))\n",
    "\\end{equation}\n",
    "$$\n",
    "The shape of $\\delta^L$ should be `(number of neurons in final layer, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_layer_error(y, a_L, z_L):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Challenge: `hidden_layer_error`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that determines the error of each neuron in a hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Input**\n",
    "1. `w_next_layer`: The weights for the next layer in the network (i.e. if the current layer is layer $l$, then `w_next_layer` is $w^{l+1}$). Shape is `(number of neurons in next layer, number of neurons in current layer)`.\n",
    "1. `d_next_layer`: The error for the next layer in the network (i.e. $\\delta^{l+1}$). Shape is `(number of neurons in next layer, 1)`.\n",
    "1. `z`: The weighted input of the current layer (i.e. $z^L$). Shape is `(number of neurons in current layer, 1)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Output**\n",
    "\n",
    "Your function should output the value $\\delta^l$ using the rule:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\delta^l(x) = \\left(w^{l + 1}\\right)^T \\delta^{l+1}\\ \\odot\\ \\sigma ' (z^l)\n",
    "\\end{equation}.\n",
    "$$\n",
    "The shape of the output should be `(number of neurons in current layer, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_layer_error(w_next_layer, d_next_layer, z):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Challenge: `weights_grad`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that returns the gradient of the weights in a single layer of a network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Input**\n",
    "\n",
    "1. `a_prev_layer`: The activations from the previous layer (i.e. $a^{l-1}$). Shape will be `(number neurons in prev layer, 1)`.\n",
    "1. `d_l`: Error of each nueron in the current layer. Shape will be `(number of observations, number neurons in current layer)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Output**\n",
    "\n",
    "The output should be a numpy array with shape `(number of neurons in curr layer, number of neurons in prev layer)`. The element in the $j^{th}$ row and $k^{th}$ column should be the value $\n",
    "\\begin{equation}\n",
    "\\frac{\\partial MSE}{\\partial w^l_{jk}} = a^{l - 1}_k \\delta^l_j\n",
    "\\end{equation}\n",
    "$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_grad(a_prev_layer, d_l):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the partial derivative of MSE with respect to the bias of a neuron is equal to the neuron's error (i.e. $\n",
    "\\begin{equation}\n",
    "\\frac{\\partial MSE}{\\partial b^l_j} = \\delta^l_j\n",
    "\\end{equation}\n",
    "$) we won't write a separate function to compute the gradient of MSE with respect to a layer's biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Challenge: `backprop`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got all of the essential building blocks for implementing backprop. Study the neural network implementation below. In particular, you will likely find the `feed_forward` method to be rather helpful. `feed_forward` accepts a single observation in the training data set and feeds it forward through the network. It returns two lists:\n",
    "1. `zs`: A list of the weighted input vectors ($z^l$) at each layer in the network, starting with the first hidden layer.\n",
    "1. `activations`: A list of the activation vectors ($a^l$) at each layer in the network, starting with the input layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Description**\n",
    "\n",
    "You will complete the backprop method below. Your method should feed each observation in the training data set, `X_train`, through the network one at a time. Use the functions you created above to compute the partial derivatives $\\frac{\\partial MSE}{w_{jk}^l}$ and $\\frac{\\partial MSE}{b_j^l}$ once for each observation in the training set. For a specific weight in the network, like $w^2_{12}$, we will return the mean value of $\\frac{\\partial MSE}{w_{12}^2}$ across each of the training observations.\n",
    "\n",
    "**Function Input**\n",
    "1. `X_train`: Array of training data with shape `(number of observations, number of neurons in input layer)`.\n",
    "1. `y_train`: Array of labels with shape `(number of observations, number of neurons in final layer)`.\n",
    "\n",
    "**Function Output**\n",
    "\n",
    "You should output a tuple, `(w_grads, b_grads)`, that holds two lists.\n",
    "1. `w_grads`: A list of the gradients of weights in the network, layer by layer. For instance, the very first entry in `w_grads` should be a numpy array with shape `(neurons in first hidden layer, neurons in input layer)`, and the entry in the first row and second column of this array should be the mean value of $\\frac{\\partial MSE}{w_{12}^2}$ across each of the training observations.\n",
    "1. `b_grads`: A list of the gradients of biases in the network, layer by layer. This first entry in `b_grads` should be a numpy array with shape `(number of neurons in first hidden layer, 1)` that holds the mean values of $\\frac{\\partial MSE}{b_{jk}^2}$ across all observations in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Challenge: `update_parameters`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `update_parameters` function should use `backprop` to compute the partial derivatives of the MSE loss function with respect to each of the weights and biases in the network. Then `update_parameters` should reassign the `self.weights` and `self.biases` attributes according to the rules $w_{jk}^l := w_{jk}^l - \\eta\\frac{\\partial MSE}{\\partial w_{jk}^l}$ and $b^l_j := b^l_j - \\eta \\frac{\\partial MSE}{\\partial b^l_j}$, where $\\eta$ is the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Challenge: `train`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `train` method should use the provided training data to update the network parameters as many times as specified by the `epochs` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNeuralNet:\n",
    "    def __init__(self, shape=(2,2,1)):\n",
    "        \"\"\"\n",
    "        Initializes the weights and biases for the network.\n",
    "        kwarg: shape, a tuple describing number of neurons in each layer of the network\n",
    "        \"\"\"\n",
    "        self.shape = shape\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        for n_rows, n_cols in zip(shape[1:], shape[:-1]):\n",
    "            w = np.random.uniform(-1, 1, size=(n_rows, n_cols))\n",
    "            b = np.random.uniform(-1, 1, size=(n_rows, 1))\n",
    "            self.weights.append(w)\n",
    "            self.biases.append(b)\n",
    "    \n",
    "    def feed_forward(self, observation):\n",
    "        a = np.array(observation).reshape(-1,1)\n",
    "        activations = [a]\n",
    "        zs = []\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(w,a) + b\n",
    "            zs.append(z)\n",
    "            a = activation(z)\n",
    "            activations.append(a)\n",
    "        return zs, activations\n",
    "        \n",
    "    def backprop(self, X_train, y_train):\n",
    "        pass\n",
    "    \n",
    "    def update_parameters(self, X_train, y_train, learning_rate):\n",
    "        pass\n",
    " \n",
    "    def train(self, X_train, y_train, learning_rate, epochs):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Congratulations on implementing a working neural network! Before moving on to larger data sets, try training your network on some of the data sets provided in `feed-forward.ipynb`. Experiment with the learning rate and number of epochs you train with. Remember to reserve test data to test how well your network performs on unseen data.* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
