{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Convolutional-Neural-Networks\" data-toc-modified-id=\"Convolutional-Neural-Networks-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Convolutional Neural Networks</a></span><ul class=\"toc-item\"><li><span><a href=\"#Network-Architecture\" data-toc-modified-id=\"Network-Architecture-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Network Architecture</a></span></li><li><span><a href=\"#Data-Layer\" data-toc-modified-id=\"Data-Layer-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Data Layer</a></span></li><li><span><a href=\"#Convolution,-Max-Pooling,-and-ReLu\" data-toc-modified-id=\"Convolution,-Max-Pooling,-and-ReLu-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Convolution, Max Pooling, and ReLu</a></span></li><li><span><a href=\"#Fully-Connected-Layer\" data-toc-modified-id=\"Fully-Connected-Layer-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Fully Connected Layer</a></span></li><li><span><a href=\"#Cost-and-Accuracy\" data-toc-modified-id=\"Cost-and-Accuracy-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Cost and Accuracy</a></span></li><li><span><a href=\"#Configuring-the-Network\" data-toc-modified-id=\"Configuring-the-Network-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Configuring the Network</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "Today we'll configure and train our first convolutional neural network! We'll train our network on a classic computer vision data set - MNIST. The MNIST data is a collection of 28x28 grayscale (i.e. single-channel) images of handwrittend digits (numbers 0-9). We'll train our network to classify digits. TensorFlow gives us access to the MNIST dataset, and has preprocessed the images so that the pixel values are between 0 and 1 rather than 0 and 255. \n",
    "\n",
    "*Run the cell below to import TensorFlow and the MNIST data set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `input_data.read_data_sets` method has downloaded and stored the MNIST data in a new directory called `./data`. The variable we saved - `data` - contains training, test, and validation data. You can access the training images at `data.train.images` and the corresponding labels at `data.train.labels`. The data object also has a data generator method to produce mini-batches - `data.train.next_batch`.\n",
    "\n",
    "Note that when we imported our dataset, we passed the kwarg `one_hot`. This specifies that our labels should be given to us in a \"one-hot\" encoding. Instead of labeling each image with an integer from 0 to 9 representing which digit it is, we label our images with a vector with ten entries. One position in the vector should be a 1, while the rest of the entries should be 0. For instance, in a one-hot encoding, we would label an image of the digit 0 with the vector:\n",
    "\n",
    "$$\\begin{bmatrix}1&0&0&0&0&0&0&0&0&0\\end{bmatrix},$$\n",
    "\n",
    "and the digit 5 would be labeled with the vector:\n",
    "\n",
    "$$\\begin{bmatrix}0&0&0&0&0&1&0&0&0&0\\end{bmatrix}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture\n",
    "We will create a network with two convolutional layers. After each convolution, we will apply 2x2 max pooling, and then ReLu activation. After two convolutions, we will use a fully connected layer with one neuron for each class of digit (i.e. each neuron in the fc layer is meant to detect the presence of a particular digit). We then apply a softmax activation, which turns the output of the final layer into a probability distribution (i.e. maintains their relative activation levels but scales them so that the sum of all activation in the layer is 1). Refer to the diagram below:\n",
    "\n",
    "<img src=\"images/network-architecture.png\" style=\"height: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Layer\n",
    "\n",
    "The data layer is configured below. Since the images are given to us as one-dimensional vectors, we will reshape the raw input so it'll be an appropriate shape for convolution. Also note that if then size of a tensor in a certain dimension is unkown, you may pass `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('data_layer'):\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=[None, 28*28], name=\"raw_input\")\n",
    "    X_images = tf.reshape(X, shape=[-1,28,28,1])\n",
    "    y = tf.placeholder(dtype=tf.float32, shape=[None, 10], name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution, Max Pooling, and ReLu\n",
    "Below, we will write a function that we will use to create the two Conv + Max Pool + ReLu layers.\n",
    "\n",
    "* input:\n",
    "    1. `input_tensor`: a 4D tensor with shape [`n_images`, `height`, `width`, `n_input_channels`]\n",
    "    1. `n_input_channels`: the number of input channels for each image (a gray-scale image has a single channel, while an rgb image has three)\n",
    "    1. `filter_size`: the size of the convolutional filters we will use\n",
    "    1. `n_filters`: the number of filters/depth of the convolutional layer. This will correspond to the number of channels that are output from this layer.\n",
    "    1. `name`: a name to create a name_scope for the layer.\n",
    "    \n",
    "* output:\n",
    "    1. `(relu, weights, bias)`: where `relu` is the tensorflow activation operation, and `weights` and `bias` are the tensorflow variables representing the weights/biases used in the convolutional layer.\n",
    "    \n",
    "Within a name scope corresponding to the parameter `name`, you function should create the following operations:\n",
    "\n",
    "1. `weights`: a tensorflow variable with shape [filter_size, filter_size, n_input_channels, n_filters]. Pick an appropriate initializer.\n",
    "1. `bias`: a variable with shape [n_filters]. Pick an appropriate initializer.\n",
    "1. `conv`: a `tf.nn.conv2d` operation, which relies on `input_tensor` and `weights`. Strides should be 1 in each dimension, and padding should be \"SAME\".\n",
    "1. `conv_and_bias`: the result of adding `bias` to `conv`.\n",
    "1. `max_pool`: a `tf.nn.max_pool` layer applied to `conv_and_bias`. The kernel size should be [1,2,2,1], and stride should also be [1,2,2,1].\n",
    "1. `relu`: finally, apply a `tf.nn.relu` activation to `max_pool`. Your function should return a tuple consisting of (`relu`, `weights`, `bias`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_w_pool_and_relu(input_tensor, n_input_channels = 1, filter_size = 5, n_filters = 10,\n",
    "                         name = \"conv_layer\"):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Layer\n",
    "At the end of our network, we will use a fully connected layer. We want one neuron for each class our data can belong to. That way, we will train each neuron in the layer to recognize digits that belong to their class.\n",
    "\n",
    "* input:\n",
    "    1. `input_tensor`: This will be a tensor which comes from the output of one of our convolutional layers. As such, its shape will be [`n_images`, `height`, `width`, `n_input_channels`] \n",
    "    1. `name`: a name to create a name_scope for the layer.\n",
    "   \n",
    "Within a name scope corresponding to the parameter `name`, you function should create the following operations:\n",
    "\n",
    "* `flattened`: Your function should first flatten the `input_tensor` using `tf.reshape` so that it has dimensions [`n_images`, `height * width * n_input_channels`].\n",
    "* `weights`: a `tf.Variable` with appropriate dimensions for a fully connected layer with 10 neurons.\n",
    "* `bias`: a `tf.Variable` with appropriate dimensions for the bias of a layer with 10 neurons.\n",
    "* `logits`: the result of applying weights to the `flattened` input and adding on the bias.\n",
    "* `y_pred`: the result of applying `tf.nn.softmax` to `logits`.\n",
    "\n",
    "Your function should return the tuple `(logits, y_pred)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_layer(input_tensor, name):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost and Accuracy\n",
    "Now we'll develop the operations necessary to assess the performance of our network. We will use cross entropy as our loss function, and will also create an accuracy operation that calculates the percent of images that are correctly classified.\n",
    "\n",
    "* input:\n",
    "    1. `logits`: the raw output of the fully connected layer without softmax applied\n",
    "    1. `y_pred`: predictions made by the fully connected layer\n",
    "    1. `y`: the actual labels for a batch of images\n",
    "    1. `name`: a name to create a name_scope for the layer.\n",
    "   \n",
    "Within a name scope corresponding to the parameter `name`, you function should create the following operations:\n",
    "\n",
    "* `cross_ent`: Use `tf.nn.softmax_cross_entropy_with_logits` to create a node that computes the cross entropy for each image in the batch.\n",
    "* `cost`: Use `tf.reduce_mean` to compute the mean cross entropy for images in the batch.\n",
    "* `y_cls` and `y_pred_cls`: Use `tf.argmax` to turn the one-hot encoded tensors `y` and `y_pred` into tensors of integers (where the integers represent classes).\n",
    "* `correct_predictions`: Use `tf.cast` and `tf.equal` to create a tensor of type `tf.float32` with shape [`n_images`]. The value of the $i^{th}$ entry should be 0 if the $ith$ entry in `y_cls` and `y_pred` don't match, and should be 1 if they do match.\n",
    "* `accuracy`: Use `tf.reduce_mean` to create a node the tracks the percent of images that are correctly classified by our model.\n",
    "\n",
    "Our function should return the tuple `(cost, accuracy)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_and_accuracy(logits, y_pred, y, name):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Network\n",
    "In the cell below, we configure the forward pass and cost/accuracy calculation portions of our network, using the functions we wrote above.\n",
    "\n",
    "The last operation required to get our network functioning properly is an optimizer! Create a variable, `optimizer`, using the `tf.train.AdamOptimizer` with a `learning_rate` of `1e-4` to optimize the `cost` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1, weights1, bias1 = conv_w_pool_and_relu(X_images, name=\"conv1\")\n",
    "conv2, weights2, bias2 = conv_w_pool_and_relu(conv1, n_input_channels=10, name=\"conv2\")\n",
    "logits, y_pred = fc_layer(conv2, name=\"fc1\")\n",
    "cost, accuracy = cost_and_accuracy(logits, y_pred, y, name=\"cost_and_accuracy\")\n",
    "# Create optimizer below!\n",
    "optimizer = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, let's create summary operations to track some important stats as our model trains.\n",
    "\n",
    "* Create histogram summaries for `weights1`, `bias1`, `weights2`, and `bias2`\n",
    "* Create scalar summaries for `cost` and `accuracy`\n",
    "* Use `tf.summary.merge_all` to create a master summary operation, and save the result to `summary_op`.\n",
    "* Create a `train_writer` to write our summaries related to training to the directory `tensorboard/training`.\n",
    "* Create a `validation_writer` to write summaries related to validation data to the directory `tensorboard/validation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to start a session!\n",
    "\n",
    "* Create/run a global variable initializer\n",
    "* Create a loop that will iterate through the number of epochs we are training for\n",
    "    * Within that, create a loop to iterate through the number of batches per epoch\n",
    "        * Use `data.train.next_batch(batch_size)` and save the resulting `X_batch` and `y_batch`\n",
    "        * Create a feed dict for placeholders `X` and `y` - we will pass these placeholders `X_batch` and `y_batch`\n",
    "        * Run the `optimizer` and `summary_op` nodes\n",
    "        * Use the `train_writer` to write the resulting summary\n",
    "    * After each epoch, run the `summary_op` node, passing a feed_dict that holds the validation data (`data.validation.images` and `data.validation.labels`)\n",
    "    * Use the `validation_writer` to write the resulting summary\n",
    "    * Use the saver to save the model to the directory `model`. Make sure to use a `global_step` corresponding to the current epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "n_epochs = 100\n",
    "batch_size = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
